This project is about creating a vision-based autonomous robot that can detect and navigate through polybags in garden environments. The robot uses a NVIDIA Jetson Nano as its computing platform, running on Linux OS. The main components of the project are:

A custom deep learning network that uses OpenCV, TensorFlow and Keras to process images from a camera and identify polybags with high accuracy. The network is trained on 300 datasets of garden images with different lighting and weather conditions.
A custom navigation algorithm that uses bounding box analysis to determine the optimal path for the robot to approach and avoid polybags. The algorithm also takes into account the robot’s speed, orientation and distance from the polybags.
A Docker container that encapsulates the dependencies and libraries needed to run the project, ensuring easy deployment and portability.
A Python script that integrates the deep learning network, the navigation algorithm and the robot’s hardware components, such as motors, sensors and camera.
The project demonstrates the use of cutting-edge technologies and techniques to create a practical solution for a real-world problem. The project also showcases the skills and knowledge in computer vision, deep learning, autonomous robotics and software-hardware integration. The project received the highest distinction for its innovation, performance and impact


